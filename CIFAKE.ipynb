{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqsb3AyTsVdW"
      },
      "source": [
        "이 노트북에서는 레퍼런스 논문에서 소개된 모델을 구현하고, 테스트하는 코드를 실행하였다.\n",
        "아래는 초기 설정을 위한 코드이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "dKPzkDc9tIgE",
        "outputId": "23dc45a1-598f-4a13-94df-00ba03d44c23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-063245bd-c96e-48b1-8542-c268279f56f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-063245bd-c96e-48b1-8542-c268279f56f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # kaggle.json 업로드\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7cDvUAJTKe-Y"
      },
      "outputs": [],
      "source": [
        "import kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8YF2K6Kvvef",
        "outputId": "92ccd8e3-175b-4650-a9ed-221ccf61d3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
            "License(s): other\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images\n",
        "!unzip -q cifake-real-and-ai-generated-synthetic-images.zip\n",
        "!pip install kaggle tensorflow matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NKafl9lqrZSp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "import itertools\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cr_0QHKYrevX"
      },
      "outputs": [],
      "source": [
        "def load_data_from_directory(base_path, img_height=32, img_width=32, batch_size=128, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    디렉토리 구조에 맞게 이미지 데이터를 로드하고, 학습 데이터의 일부를 검증 데이터로 분할합니다.\n",
        "    디렉토리 구조:\n",
        "    - base_path/\n",
        "        - train/\n",
        "            - FAKE/\n",
        "            - REAL/\n",
        "        - test/\n",
        "            - FAKE/\n",
        "            - REAL/\n",
        "    \"\"\"\n",
        "    print(\"데이터 로드 중...\")\n",
        "\n",
        "    # 훈련 데이터셋 로드 (validation_split 사용)\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        os.path.join(base_path, 'train'),\n",
        "        validation_split=validation_split,\n",
        "        subset=\"training\",  # 훈련 부분만 가져옴\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        class_names=['FAKE', 'REAL']\n",
        "    )\n",
        "\n",
        "    # 검증 데이터셋 로드 (train 폴더에서 validation_split 비율로 분할)\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        os.path.join(base_path, 'train'),\n",
        "        validation_split=validation_split,\n",
        "        subset=\"validation\",  # 검증 부분만 가져옴\n",
        "        seed=123,  # 동일한 시드 사용으로 훈련/검증 데이터가 겹치지 않게 함\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        class_names=['FAKE', 'REAL']\n",
        "    )\n",
        "\n",
        "    # 테스트 데이터셋 로드 (평가용)\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        os.path.join(base_path, 'test'),\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        class_names=['FAKE', 'REAL']\n",
        "    )\n",
        "\n",
        "    # 데이터셋 크기 계산 (배치 수)\n",
        "    train_batches = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "    val_batches = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "    test_batches = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "\n",
        "    print(f\"훈련 데이터셋 배치 수: {train_batches}\")\n",
        "    print(f\"검증 데이터셋 배치 수: {val_batches}\")\n",
        "    print(f\"테스트 데이터셋 배치 수: {test_batches}\")\n",
        "\n",
        "    # 데이터셋 최적화\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    train_ds = train_ds.cache().shuffle(10000).repeat().prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    print(\"훈련, 검증 및 테스트 데이터셋 로드 완료!\")\n",
        "\n",
        "    return train_ds, val_ds, test_ds, train_batches, val_batches, test_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uUY-ttB6r5en"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    num_conv_layers=2,      # 컨볼루션 레이어 개수 (기본값: 2)\n",
        "    conv_filters=32,  # 각 컨볼루션 레이어의 필터 수 (기본값: 32)\n",
        "    num_dense_layers=3,     # Dense 레이어 개수 (기본값: 3)\n",
        "    dense_neurons=64,  # 각 Dense 레이어의 뉴런 수 (기본값: 64)\n",
        "    dropout_rate=0.3        # Dropout 비율 (기본값: 0.3)\n",
        "):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(32,32,3)))\n",
        "\n",
        "    # Conv 레이어 (num_conv_layers 층의 conv_filters개의 필터)\n",
        "    for i in range(num_conv_layers):\n",
        "        model.add(Conv2D(\n",
        "            filters=conv_filters,\n",
        "            kernel_size=(3, 3),\n",
        "            activation='relu',\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense 레이어 (num_dense_layers 층의 dense_neurons개의 뉴런)\n",
        "    for j in range(num_dense_layers):\n",
        "        model.add(Dense(\n",
        "            units=dense_neurons,\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # 출력 레이어\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hfpe3eGHSgWt"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_ds, val_ds, train_batches, val_batches, epochs=20, batch_size = 128):\n",
        "    \"\"\"\n",
        "    모델 훈련 함수\n",
        "\n",
        "    Args:\n",
        "        model: 훈련할 모델\n",
        "        train_ds: 훈련 데이터셋\n",
        "        val_ds: 검증 데이터셋\n",
        "        epochs: 훈련 에포크 수\n",
        "    \"\"\"\n",
        "\n",
        "    # 콜백 설정\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=5,\n",
        "        min_lr=0.0001\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_batches,\n",
        "        validation_data=val_ds,\n",
        "        validation_steps=val_batches,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 경로 지정\n",
        "base_path = './'  # 데이터셋이 있는 경로\n",
        "batch_size=128\n",
        "epochs_num=20\n",
        "\n",
        "# 데이터 로드 (validation_split 사용)\n",
        "train_ds, val_ds, test_ds, train_batches, val_batches, test_batches = load_data_from_directory(\n",
        "    base_path,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2  # 학습 데이터의 20%를 검증 데이터로 사용\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Uf9ZlmIRZAg",
        "outputId": "fe9d364d-4428-4394-ddc7-b3977d068f0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드 중...\n",
            "Found 100000 files belonging to 2 classes.\n",
            "Using 80000 files for training.\n",
            "Found 100000 files belonging to 2 classes.\n",
            "Using 20000 files for validation.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "훈련 데이터셋 배치 수: 625\n",
            "검증 데이터셋 배치 수: 157\n",
            "테스트 데이터셋 배치 수: 157\n",
            "훈련, 검증 및 테스트 데이터셋 로드 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmIMp-4Zr7K5",
        "outputId": "9b52ee74-12ab-4c01-c1f7-413ba97f8ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.8535 - loss: 0.3373 - precision_20: 0.8449 - recall_20: 0.8658 - val_accuracy: 0.8360 - val_loss: 0.4649 - val_precision_20: 0.7597 - val_recall_20: 0.9828 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.1832 - precision_20: 0.9252 - recall_20: 0.9268 - val_accuracy: 0.9363 - val_loss: 0.1637 - val_precision_20: 0.9271 - val_recall_20: 0.9471 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.1518 - precision_20: 0.9419 - recall_20: 0.9396 - val_accuracy: 0.9379 - val_loss: 0.1577 - val_precision_20: 0.9265 - val_recall_20: 0.9512 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1363 - precision_20: 0.9481 - recall_20: 0.9464 - val_accuracy: 0.9229 - val_loss: 0.1979 - val_precision_20: 0.9686 - val_recall_20: 0.8739 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.1191 - precision_20: 0.9552 - recall_20: 0.9539 - val_accuracy: 0.9424 - val_loss: 0.1594 - val_precision_20: 0.9441 - val_recall_20: 0.9405 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9581 - loss: 0.1085 - precision_20: 0.9590 - recall_20: 0.9577 - val_accuracy: 0.9398 - val_loss: 0.1614 - val_precision_20: 0.9633 - val_recall_20: 0.9143 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9620 - loss: 0.0998 - precision_20: 0.9631 - recall_20: 0.9611 - val_accuracy: 0.9344 - val_loss: 0.1775 - val_precision_20: 0.9599 - val_recall_20: 0.9065 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.0904 - precision_20: 0.9657 - recall_20: 0.9655 - val_accuracy: 0.9367 - val_loss: 0.1866 - val_precision_20: 0.9146 - val_recall_20: 0.9634 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0644 - precision_20: 0.9778 - recall_20: 0.9766 - val_accuracy: 0.9527 - val_loss: 0.1369 - val_precision_20: 0.9509 - val_recall_20: 0.9547 - learning_rate: 2.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.0526 - precision_20: 0.9820 - recall_20: 0.9809 - val_accuracy: 0.9467 - val_loss: 0.1453 - val_precision_20: 0.9703 - val_recall_20: 0.9217 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0484 - precision_20: 0.9838 - recall_20: 0.9823 - val_accuracy: 0.9502 - val_loss: 0.1533 - val_precision_20: 0.9652 - val_recall_20: 0.9340 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0451 - precision_20: 0.9844 - recall_20: 0.9829 - val_accuracy: 0.9486 - val_loss: 0.1493 - val_precision_20: 0.9665 - val_recall_20: 0.9294 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0409 - precision_20: 0.9866 - recall_20: 0.9854 - val_accuracy: 0.9542 - val_loss: 0.1442 - val_precision_20: 0.9536 - val_recall_20: 0.9548 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0381 - precision_20: 0.9875 - recall_20: 0.9869 - val_accuracy: 0.9460 - val_loss: 0.1963 - val_precision_20: 0.9222 - val_recall_20: 0.9741 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0314 - precision_20: 0.9893 - recall_20: 0.9896 - val_accuracy: 0.9486 - val_loss: 0.1771 - val_precision_20: 0.9292 - val_recall_20: 0.9712 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0310 - precision_20: 0.9899 - recall_20: 0.9902 - val_accuracy: 0.9541 - val_loss: 0.1462 - val_precision_20: 0.9523 - val_recall_20: 0.9560 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0276 - precision_20: 0.9917 - recall_20: 0.9913 - val_accuracy: 0.9528 - val_loss: 0.1617 - val_precision_20: 0.9408 - val_recall_20: 0.9664 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0267 - precision_20: 0.9912 - recall_20: 0.9911 - val_accuracy: 0.9467 - val_loss: 0.1923 - val_precision_20: 0.9238 - val_recall_20: 0.9736 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 0.0264 - precision_20: 0.9925 - recall_20: 0.9918 - val_accuracy: 0.9527 - val_loss: 0.1557 - val_precision_20: 0.9638 - val_recall_20: 0.9407 - learning_rate: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "model_base = build_model(\n",
        "    num_conv_layers=2,\n",
        "    conv_filters=32,\n",
        "    num_dense_layers=1,\n",
        "    dense_neurons=64,\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "\n",
        "# 모델 컴파일\n",
        "model_base.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "history_base = train_model(\n",
        "    model_base,\n",
        "    train_ds, val_ds,\n",
        "    train_batches, val_batches,\n",
        "    epochs=epochs_num,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터셋에서 실제 레이블 추출\n",
        "y_true = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# 모델로 예측 수행\n",
        "y_pred = model_base.predict(test_ds)\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "print('model_base : result')\n",
        "print(classification_report(y_true, y_pred, target_names=['FAKE', 'REAL'], digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYyLKR4vLg2f",
        "outputId": "cf72e226-23ac-430c-8acb-582b9150a223"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "model_base : result\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE     0.9540    0.9488    0.9514     10000\n",
            "        REAL     0.9491    0.9543    0.9517     10000\n",
            "\n",
            "    accuracy                         0.9516     20000\n",
            "   macro avg     0.9516    0.9516    0.9515     20000\n",
            "weighted avg     0.9516    0.9516    0.9515     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = history_base\n",
        "\n",
        "# 학습 곡선 시각화\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Loss 곡선\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy 곡선\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "L4l6DEa0WKw0",
        "outputId": "2de2991d-1937-4c7e-8226-afd201dcf5ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# 1단계: Conv 레이어 그리드 탐색\n",
        "def grid_search_conv():\n",
        "    conv_results = []\n",
        "    conv_layer_options = [1, 2, 3]\n",
        "    conv_filter_options = [16, 32, 64]\n",
        "\n",
        "    for num_layers, filter_size in itertools.product(conv_layer_options, conv_filter_options):\n",
        "\n",
        "        # 모델 생성 (Dense 레이어는 기본값 고정)\n",
        "        model = build_model(\n",
        "            num_conv_layers=num_layers,\n",
        "            conv_filters=filter_size,\n",
        "            num_dense_layers=1,\n",
        "            dense_neurons=64,\n",
        "            dropout_rate=0.3\n",
        "        )\n",
        "\n",
        "        # 모델 컴파일\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "        )\n",
        "\n",
        "        # 모델 훈련\n",
        "        history = train_model(\n",
        "            model,\n",
        "            train_ds, val_ds,\n",
        "            train_batches, val_batches,\n",
        "            epochs=epochs_num,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict(test_ds)\n",
        "        y_pred = np.round(y_pred).flatten()\n",
        "        test_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # 최고 검증 정확도 기록\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        conv_results.append({\n",
        "            'conv_layers': num_layers,\n",
        "            'filters': filter_size,\n",
        "            'val_accuracy': best_val_acc,\n",
        "            'test_accuracy': test_acc\n",
        "        })\n",
        "\n",
        "    # 결과 분석\n",
        "    df_conv = pd.DataFrame(conv_results)\n",
        "    best_conv = df_conv.loc[df_conv['test_accuracy'].idxmax()]\n",
        "    print(\"\\n[1단계] Conv 레이어 최적화 결과:\")\n",
        "    print(df_conv)\n",
        "    print(f\"\\n최적 조합: Conv 층 {best_conv['conv_layers']}개, 필터 {best_conv['filters']}개\")\n",
        "\n",
        "    return best_conv\n",
        "\n",
        "# 2단계: Dense 레이어 그리드 탐색\n",
        "def grid_search_dense():\n",
        "    dense_results = []\n",
        "    dense_layer_options = [1, 2, 3]\n",
        "    dense_neuron_options = [32, 64, 128]\n",
        "\n",
        "    for num_layers, neuron_size in itertools.product(dense_layer_options, dense_neuron_options):\n",
        "\n",
        "        # 모델 생성 (Conv 레이어는 1단계 최적값 사용)\n",
        "        model = build_model(\n",
        "            num_conv_layers=2,\n",
        "            conv_filters=32,\n",
        "            num_dense_layers=num_layers,\n",
        "            dense_neurons=neuron_size,\n",
        "            dropout_rate=0.3\n",
        "        )\n",
        "\n",
        "        # 모델 컴파일\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "        )\n",
        "\n",
        "        # 모델 훈련\n",
        "        history = train_model(\n",
        "            model,\n",
        "            train_ds, val_ds,\n",
        "            train_batches, val_batches,\n",
        "            epochs=epochs_num,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict(test_ds)\n",
        "        y_pred = np.round(y_pred).flatten()\n",
        "        test_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # 최고 검증 정확도 기록\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        dense_results.append({\n",
        "            'dense_layers': num_layers,\n",
        "            'neurons': neuron_size,\n",
        "            'val_accuracy': best_val_acc,\n",
        "            'test_accuracy': test_acc\n",
        "        })\n",
        "\n",
        "    # 결과 분석\n",
        "    df_dense = pd.DataFrame(dense_results)\n",
        "    best_dense = df_dense.loc[df_dense['test_accuracy'].idxmax()]\n",
        "    print(\"\\n[2단계] Dense 레이어 최적화 결과:\")\n",
        "    print(df_dense)\n",
        "    print(f\"\\n최적 조합: Dense 층 {best_dense['dense_layers']}개, 뉴런 {best_dense['neurons']}개\")\n",
        "\n",
        "    return best_dense\n"
      ],
      "metadata": {
        "id": "LoSRWHYXZak5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_conv_params = grid_search_conv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntTO_2eEjYsD",
        "outputId": "37882efd-f2ab-4987-dca3-ef4faef2c1ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8233 - loss: 0.3918 - precision_23: 0.8117 - recall_23: 0.8429 - val_accuracy: 0.8640 - val_loss: 0.3262 - val_precision_23: 0.8013 - val_recall_23: 0.9679 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2180 - precision_23: 0.9104 - recall_23: 0.9136 - val_accuracy: 0.9004 - val_loss: 0.2435 - val_precision_23: 0.9036 - val_recall_23: 0.8964 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.1793 - precision_23: 0.9299 - recall_23: 0.9292 - val_accuracy: 0.9186 - val_loss: 0.2039 - val_precision_23: 0.9039 - val_recall_23: 0.9368 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1585 - precision_23: 0.9401 - recall_23: 0.9374 - val_accuracy: 0.8993 - val_loss: 0.2570 - val_precision_23: 0.8470 - val_recall_23: 0.9747 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1405 - precision_23: 0.9453 - recall_23: 0.9475 - val_accuracy: 0.9099 - val_loss: 0.2302 - val_precision_23: 0.8824 - val_recall_23: 0.9457 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.1294 - precision_23: 0.9482 - recall_23: 0.9497 - val_accuracy: 0.9221 - val_loss: 0.2091 - val_precision_23: 0.9365 - val_recall_23: 0.9055 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.1147 - precision_23: 0.9547 - recall_23: 0.9578 - val_accuracy: 0.9216 - val_loss: 0.2179 - val_precision_23: 0.8958 - val_recall_23: 0.9541 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.0999 - precision_23: 0.9610 - recall_23: 0.9631 - val_accuracy: 0.9064 - val_loss: 0.2514 - val_precision_23: 0.9533 - val_recall_23: 0.8544 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 0.0813 - precision_23: 0.9677 - recall_23: 0.9725 - val_accuracy: 0.9348 - val_loss: 0.1850 - val_precision_23: 0.9249 - val_recall_23: 0.9465 - learning_rate: 2.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0672 - precision_23: 0.9742 - recall_23: 0.9772 - val_accuracy: 0.9341 - val_loss: 0.1910 - val_precision_23: 0.9456 - val_recall_23: 0.9211 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0633 - precision_23: 0.9768 - recall_23: 0.9780 - val_accuracy: 0.9343 - val_loss: 0.1983 - val_precision_23: 0.9430 - val_recall_23: 0.9244 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0573 - precision_23: 0.9785 - recall_23: 0.9810 - val_accuracy: 0.9297 - val_loss: 0.2289 - val_precision_23: 0.9052 - val_recall_23: 0.9597 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0537 - precision_23: 0.9805 - recall_23: 0.9835 - val_accuracy: 0.9337 - val_loss: 0.2029 - val_precision_23: 0.9470 - val_recall_23: 0.9188 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0496 - precision_23: 0.9819 - recall_23: 0.9839 - val_accuracy: 0.9356 - val_loss: 0.2091 - val_precision_23: 0.9360 - val_recall_23: 0.9352 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0438 - precision_23: 0.9843 - recall_23: 0.9859 - val_accuracy: 0.9312 - val_loss: 0.2223 - val_precision_23: 0.9543 - val_recall_23: 0.9056 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0426 - precision_23: 0.9848 - recall_23: 0.9884 - val_accuracy: 0.9337 - val_loss: 0.2123 - val_precision_23: 0.9289 - val_recall_23: 0.9393 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0407 - precision_23: 0.9862 - recall_23: 0.9874 - val_accuracy: 0.9344 - val_loss: 0.2234 - val_precision_23: 0.9247 - val_recall_23: 0.9456 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0400 - precision_23: 0.9854 - recall_23: 0.9868 - val_accuracy: 0.9359 - val_loss: 0.2171 - val_precision_23: 0.9364 - val_recall_23: 0.9354 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0387 - precision_23: 0.9872 - recall_23: 0.9874 - val_accuracy: 0.9327 - val_loss: 0.2290 - val_precision_23: 0.9513 - val_recall_23: 0.9121 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8430 - loss: 0.3570 - precision_24: 0.8370 - recall_24: 0.8530 - val_accuracy: 0.8981 - val_loss: 0.2625 - val_precision_24: 0.8528 - val_recall_24: 0.9620 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.1999 - precision_24: 0.9202 - recall_24: 0.9223 - val_accuracy: 0.9133 - val_loss: 0.2237 - val_precision_24: 0.9515 - val_recall_24: 0.8709 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.1751 - precision_24: 0.9314 - recall_24: 0.9292 - val_accuracy: 0.8776 - val_loss: 0.2947 - val_precision_24: 0.9770 - val_recall_24: 0.7732 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1503 - precision_24: 0.9435 - recall_24: 0.9393 - val_accuracy: 0.8558 - val_loss: 0.4227 - val_precision_24: 0.7829 - val_recall_24: 0.9844 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.1300 - precision_24: 0.9497 - recall_24: 0.9508 - val_accuracy: 0.9298 - val_loss: 0.1915 - val_precision_24: 0.9172 - val_recall_24: 0.9449 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1117 - precision_24: 0.9579 - recall_24: 0.9552 - val_accuracy: 0.8295 - val_loss: 0.6243 - val_precision_24: 0.7490 - val_recall_24: 0.9908 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.1000 - precision_24: 0.9604 - recall_24: 0.9622 - val_accuracy: 0.9331 - val_loss: 0.1901 - val_precision_24: 0.9253 - val_recall_24: 0.9423 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.0907 - precision_24: 0.9654 - recall_24: 0.9648 - val_accuracy: 0.9161 - val_loss: 0.2447 - val_precision_24: 0.9623 - val_recall_24: 0.8659 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9697 - loss: 0.0811 - precision_24: 0.9700 - recall_24: 0.9697 - val_accuracy: 0.9322 - val_loss: 0.2079 - val_precision_24: 0.9365 - val_recall_24: 0.9271 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9734 - loss: 0.0710 - precision_24: 0.9739 - recall_24: 0.9730 - val_accuracy: 0.8745 - val_loss: 0.4782 - val_precision_24: 0.8072 - val_recall_24: 0.9839 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0673 - precision_24: 0.9744 - recall_24: 0.9759 - val_accuracy: 0.9299 - val_loss: 0.2328 - val_precision_24: 0.9221 - val_recall_24: 0.9392 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0635 - precision_24: 0.9765 - recall_24: 0.9772 - val_accuracy: 0.8913 - val_loss: 0.4396 - val_precision_24: 0.8339 - val_recall_24: 0.9771 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0469 - precision_24: 0.9826 - recall_24: 0.9835 - val_accuracy: 0.9380 - val_loss: 0.2066 - val_precision_24: 0.9371 - val_recall_24: 0.9389 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0366 - precision_24: 0.9882 - recall_24: 0.9879 - val_accuracy: 0.9333 - val_loss: 0.2169 - val_precision_24: 0.9588 - val_recall_24: 0.9054 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0337 - precision_24: 0.9879 - recall_24: 0.9889 - val_accuracy: 0.9387 - val_loss: 0.2166 - val_precision_24: 0.9423 - val_recall_24: 0.9345 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0326 - precision_24: 0.9892 - recall_24: 0.9888 - val_accuracy: 0.9312 - val_loss: 0.2338 - val_precision_24: 0.9603 - val_recall_24: 0.8995 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0285 - precision_24: 0.9904 - recall_24: 0.9905 - val_accuracy: 0.9295 - val_loss: 0.2485 - val_precision_24: 0.9638 - val_recall_24: 0.8925 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.3659 - precision_25: 0.8357 - recall_25: 0.8553 - val_accuracy: 0.9074 - val_loss: 0.2283 - val_precision_25: 0.9422 - val_recall_25: 0.8678 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2041 - precision_25: 0.9169 - recall_25: 0.9178 - val_accuracy: 0.8662 - val_loss: 0.3686 - val_precision_25: 0.7980 - val_recall_25: 0.9803 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.1656 - precision_25: 0.9336 - recall_25: 0.9360 - val_accuracy: 0.8964 - val_loss: 0.2581 - val_precision_25: 0.9724 - val_recall_25: 0.8158 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1410 - precision_25: 0.9454 - recall_25: 0.9460 - val_accuracy: 0.8945 - val_loss: 0.2618 - val_precision_25: 0.9720 - val_recall_25: 0.8123 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1197 - precision_25: 0.9549 - recall_25: 0.9548 - val_accuracy: 0.9337 - val_loss: 0.1799 - val_precision_25: 0.9345 - val_recall_25: 0.9328 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9606 - loss: 0.1053 - precision_25: 0.9595 - recall_25: 0.9618 - val_accuracy: 0.8629 - val_loss: 0.4772 - val_precision_25: 0.7944 - val_recall_25: 0.9788 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.0912 - precision_25: 0.9643 - recall_25: 0.9661 - val_accuracy: 0.9008 - val_loss: 0.2716 - val_precision_25: 0.9614 - val_recall_25: 0.8350 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.0775 - precision_25: 0.9686 - recall_25: 0.9736 - val_accuracy: 0.9275 - val_loss: 0.2185 - val_precision_25: 0.9160 - val_recall_25: 0.9413 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9744 - loss: 0.0686 - precision_25: 0.9748 - recall_25: 0.9740 - val_accuracy: 0.9114 - val_loss: 0.3199 - val_precision_25: 0.8674 - val_recall_25: 0.9711 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0648 - precision_25: 0.9756 - recall_25: 0.9766 - val_accuracy: 0.9169 - val_loss: 0.2574 - val_precision_25: 0.9450 - val_recall_25: 0.8853 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0468 - precision_25: 0.9821 - recall_25: 0.9845 - val_accuracy: 0.9293 - val_loss: 0.2262 - val_precision_25: 0.9675 - val_recall_25: 0.8882 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0354 - precision_25: 0.9888 - recall_25: 0.9876 - val_accuracy: 0.9399 - val_loss: 0.2070 - val_precision_25: 0.9444 - val_recall_25: 0.9349 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0321 - precision_25: 0.9885 - recall_25: 0.9902 - val_accuracy: 0.9117 - val_loss: 0.2979 - val_precision_25: 0.9748 - val_recall_25: 0.8450 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0280 - precision_25: 0.9900 - recall_25: 0.9913 - val_accuracy: 0.9399 - val_loss: 0.2258 - val_precision_25: 0.9336 - val_recall_25: 0.9471 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0248 - precision_25: 0.9911 - recall_25: 0.9924 - val_accuracy: 0.9352 - val_loss: 0.2366 - val_precision_25: 0.9169 - val_recall_25: 0.9572 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8332 - loss: 0.3840 - precision_26: 0.8241 - recall_26: 0.8512 - val_accuracy: 0.8374 - val_loss: 0.3787 - val_precision_26: 0.9771 - val_recall_26: 0.6908 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2070 - precision_26: 0.9171 - recall_26: 0.9193 - val_accuracy: 0.9167 - val_loss: 0.2120 - val_precision_26: 0.9600 - val_recall_26: 0.8695 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.1754 - precision_26: 0.9297 - recall_26: 0.9327 - val_accuracy: 0.9280 - val_loss: 0.1843 - val_precision_26: 0.9466 - val_recall_26: 0.9070 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9357 - loss: 0.1653 - precision_26: 0.9362 - recall_26: 0.9356 - val_accuracy: 0.9218 - val_loss: 0.1968 - val_precision_26: 0.9508 - val_recall_26: 0.8894 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1460 - precision_26: 0.9403 - recall_26: 0.9441 - val_accuracy: 0.9254 - val_loss: 0.1947 - val_precision_26: 0.9665 - val_recall_26: 0.8812 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.1399 - precision_26: 0.9438 - recall_26: 0.9474 - val_accuracy: 0.7344 - val_loss: 0.6506 - val_precision_26: 0.9956 - val_recall_26: 0.4705 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1305 - precision_26: 0.9494 - recall_26: 0.9468 - val_accuracy: 0.9174 - val_loss: 0.2186 - val_precision_26: 0.8755 - val_recall_26: 0.9731 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.1212 - precision_26: 0.9539 - recall_26: 0.9512 - val_accuracy: 0.9399 - val_loss: 0.1618 - val_precision_26: 0.9270 - val_recall_26: 0.9549 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.1148 - precision_26: 0.9543 - recall_26: 0.9570 - val_accuracy: 0.9111 - val_loss: 0.2345 - val_precision_26: 0.9691 - val_recall_26: 0.8492 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.1104 - precision_26: 0.9601 - recall_26: 0.9571 - val_accuracy: 0.9111 - val_loss: 0.2640 - val_precision_26: 0.8621 - val_recall_26: 0.9787 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.0995 - precision_26: 0.9606 - recall_26: 0.9616 - val_accuracy: 0.9179 - val_loss: 0.2229 - val_precision_26: 0.9663 - val_recall_26: 0.8659 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.0972 - precision_26: 0.9623 - recall_26: 0.9615 - val_accuracy: 0.9108 - val_loss: 0.2586 - val_precision_26: 0.9777 - val_recall_26: 0.8407 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.0879 - precision_26: 0.9659 - recall_26: 0.9659 - val_accuracy: 0.9395 - val_loss: 0.1806 - val_precision_26: 0.9489 - val_recall_26: 0.9289 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0744 - precision_26: 0.9742 - recall_26: 0.9711 - val_accuracy: 0.9430 - val_loss: 0.1627 - val_precision_26: 0.9353 - val_recall_26: 0.9517 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0634 - precision_26: 0.9766 - recall_26: 0.9769 - val_accuracy: 0.9327 - val_loss: 0.1905 - val_precision_26: 0.9699 - val_recall_26: 0.8930 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0633 - precision_26: 0.9767 - recall_26: 0.9778 - val_accuracy: 0.9446 - val_loss: 0.1668 - val_precision_26: 0.9428 - val_recall_26: 0.9466 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0584 - precision_26: 0.9789 - recall_26: 0.9792 - val_accuracy: 0.9435 - val_loss: 0.1653 - val_precision_26: 0.9429 - val_recall_26: 0.9441 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0586 - precision_26: 0.9791 - recall_26: 0.9797 - val_accuracy: 0.9413 - val_loss: 0.1830 - val_precision_26: 0.9334 - val_recall_26: 0.9503 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8538 - loss: 0.3422 - precision_27: 0.8481 - recall_27: 0.8613 - val_accuracy: 0.8949 - val_loss: 0.2560 - val_precision_27: 0.9557 - val_recall_27: 0.8281 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.1857 - precision_27: 0.9258 - recall_27: 0.9274 - val_accuracy: 0.8067 - val_loss: 0.4737 - val_precision_27: 0.9833 - val_recall_27: 0.6239 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.1554 - precision_27: 0.9388 - recall_27: 0.9394 - val_accuracy: 0.9115 - val_loss: 0.2351 - val_precision_27: 0.8719 - val_recall_27: 0.9646 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1365 - precision_27: 0.9479 - recall_27: 0.9467 - val_accuracy: 0.9331 - val_loss: 0.1692 - val_precision_27: 0.9390 - val_recall_27: 0.9263 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1253 - precision_27: 0.9535 - recall_27: 0.9512 - val_accuracy: 0.8750 - val_loss: 0.3702 - val_precision_27: 0.8088 - val_recall_27: 0.9821 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1143 - precision_27: 0.9565 - recall_27: 0.9560 - val_accuracy: 0.9289 - val_loss: 0.1939 - val_precision_27: 0.9747 - val_recall_27: 0.8805 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1016 - precision_27: 0.9622 - recall_27: 0.9607 - val_accuracy: 0.9130 - val_loss: 0.2223 - val_precision_27: 0.8715 - val_recall_27: 0.9689 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.0934 - precision_27: 0.9644 - recall_27: 0.9636 - val_accuracy: 0.9316 - val_loss: 0.1855 - val_precision_27: 0.9032 - val_recall_27: 0.9666 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.0849 - precision_27: 0.9685 - recall_27: 0.9660 - val_accuracy: 0.9370 - val_loss: 0.1837 - val_precision_27: 0.9156 - val_recall_27: 0.9627 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0616 - precision_27: 0.9793 - recall_27: 0.9758 - val_accuracy: 0.9503 - val_loss: 0.1395 - val_precision_27: 0.9507 - val_recall_27: 0.9497 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9827 - loss: 0.0510 - precision_27: 0.9837 - recall_27: 0.9816 - val_accuracy: 0.9492 - val_loss: 0.1542 - val_precision_27: 0.9349 - val_recall_27: 0.9656 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.0451 - precision_27: 0.9850 - recall_27: 0.9850 - val_accuracy: 0.9506 - val_loss: 0.1493 - val_precision_27: 0.9482 - val_recall_27: 0.9533 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0402 - precision_27: 0.9864 - recall_27: 0.9871 - val_accuracy: 0.9523 - val_loss: 0.1498 - val_precision_27: 0.9556 - val_recall_27: 0.9487 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 0.0386 - precision_27: 0.9867 - recall_27: 0.9865 - val_accuracy: 0.9492 - val_loss: 0.1533 - val_precision_27: 0.9484 - val_recall_27: 0.9502 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0352 - precision_27: 0.9888 - recall_27: 0.9882 - val_accuracy: 0.9483 - val_loss: 0.1585 - val_precision_27: 0.9620 - val_recall_27: 0.9335 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0304 - precision_27: 0.9905 - recall_27: 0.9903 - val_accuracy: 0.9518 - val_loss: 0.1613 - val_precision_27: 0.9598 - val_recall_27: 0.9432 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0292 - precision_27: 0.9917 - recall_27: 0.9904 - val_accuracy: 0.9510 - val_loss: 0.1612 - val_precision_27: 0.9572 - val_recall_27: 0.9442 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0270 - precision_27: 0.9919 - recall_27: 0.9911 - val_accuracy: 0.9484 - val_loss: 0.1717 - val_precision_27: 0.9661 - val_recall_27: 0.9294 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0255 - precision_27: 0.9925 - recall_27: 0.9925 - val_accuracy: 0.9491 - val_loss: 0.1705 - val_precision_27: 0.9641 - val_recall_27: 0.9328 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0250 - precision_27: 0.9915 - recall_27: 0.9930 - val_accuracy: 0.9494 - val_loss: 0.1640 - val_precision_27: 0.9562 - val_recall_27: 0.9419 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8567 - loss: 0.3418 - precision_28: 0.8471 - recall_28: 0.8727 - val_accuracy: 0.7632 - val_loss: 0.8223 - val_precision_28: 0.6799 - val_recall_28: 0.9943 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9310 - loss: 0.1758 - precision_28: 0.9310 - recall_28: 0.9312 - val_accuracy: 0.9297 - val_loss: 0.1765 - val_precision_28: 0.9548 - val_recall_28: 0.9019 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.1461 - precision_28: 0.9408 - recall_28: 0.9423 - val_accuracy: 0.9333 - val_loss: 0.1771 - val_precision_28: 0.9141 - val_recall_28: 0.9563 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.1256 - precision_28: 0.9523 - recall_28: 0.9489 - val_accuracy: 0.9283 - val_loss: 0.1865 - val_precision_28: 0.9604 - val_recall_28: 0.8933 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9589 - loss: 0.1084 - precision_28: 0.9603 - recall_28: 0.9575 - val_accuracy: 0.9340 - val_loss: 0.1819 - val_precision_28: 0.9283 - val_recall_28: 0.9405 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9640 - loss: 0.0930 - precision_28: 0.9647 - recall_28: 0.9631 - val_accuracy: 0.9300 - val_loss: 0.1845 - val_precision_28: 0.9668 - val_recall_28: 0.8905 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.0803 - precision_28: 0.9710 - recall_28: 0.9691 - val_accuracy: 0.9295 - val_loss: 0.1846 - val_precision_28: 0.8955 - val_recall_28: 0.9725 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9812 - loss: 0.0540 - precision_28: 0.9806 - recall_28: 0.9816 - val_accuracy: 0.9548 - val_loss: 0.1246 - val_precision_28: 0.9655 - val_recall_28: 0.9432 - learning_rate: 2.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0409 - precision_28: 0.9868 - recall_28: 0.9858 - val_accuracy: 0.9558 - val_loss: 0.1363 - val_precision_28: 0.9487 - val_recall_28: 0.9637 - learning_rate: 2.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.0331 - precision_28: 0.9897 - recall_28: 0.9897 - val_accuracy: 0.9574 - val_loss: 0.1324 - val_precision_28: 0.9590 - val_recall_28: 0.9555 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0289 - precision_28: 0.9914 - recall_28: 0.9906 - val_accuracy: 0.9567 - val_loss: 0.1324 - val_precision_28: 0.9624 - val_recall_28: 0.9504 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0249 - precision_28: 0.9924 - recall_28: 0.9920 - val_accuracy: 0.9528 - val_loss: 0.1470 - val_precision_28: 0.9506 - val_recall_28: 0.9553 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0215 - precision_28: 0.9932 - recall_28: 0.9934 - val_accuracy: 0.9537 - val_loss: 0.1570 - val_precision_28: 0.9449 - val_recall_28: 0.9635 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0174 - precision_28: 0.9947 - recall_28: 0.9952 - val_accuracy: 0.9556 - val_loss: 0.1538 - val_precision_28: 0.9553 - val_recall_28: 0.9560 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0156 - precision_28: 0.9958 - recall_28: 0.9959 - val_accuracy: 0.9559 - val_loss: 0.1525 - val_precision_28: 0.9634 - val_recall_28: 0.9477 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0131 - precision_28: 0.9972 - recall_28: 0.9962 - val_accuracy: 0.9556 - val_loss: 0.1614 - val_precision_28: 0.9503 - val_recall_28: 0.9615 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0119 - precision_28: 0.9966 - recall_28: 0.9971 - val_accuracy: 0.9553 - val_loss: 0.1619 - val_precision_28: 0.9669 - val_recall_28: 0.9429 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0116 - precision_28: 0.9966 - recall_28: 0.9974 - val_accuracy: 0.9554 - val_loss: 0.1720 - val_precision_28: 0.9518 - val_recall_28: 0.9595 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8129 - loss: 0.4159 - precision_29: 0.8036 - recall_29: 0.8273 - val_accuracy: 0.8982 - val_loss: 0.2445 - val_precision_29: 0.8695 - val_recall_29: 0.9370 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2147 - precision_29: 0.9123 - recall_29: 0.9153 - val_accuracy: 0.9119 - val_loss: 0.2181 - val_precision_29: 0.9504 - val_recall_29: 0.8690 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.1839 - precision_29: 0.9266 - recall_29: 0.9246 - val_accuracy: 0.8947 - val_loss: 0.2572 - val_precision_29: 0.9697 - val_recall_29: 0.8147 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.1665 - precision_29: 0.9351 - recall_29: 0.9358 - val_accuracy: 0.9245 - val_loss: 0.1918 - val_precision_29: 0.8974 - val_recall_29: 0.9586 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.1580 - precision_29: 0.9388 - recall_29: 0.9363 - val_accuracy: 0.9294 - val_loss: 0.1827 - val_precision_29: 0.9054 - val_recall_29: 0.9590 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1489 - precision_29: 0.9446 - recall_29: 0.9401 - val_accuracy: 0.8680 - val_loss: 0.3185 - val_precision_29: 0.9767 - val_recall_29: 0.7538 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.1435 - precision_29: 0.9439 - recall_29: 0.9447 - val_accuracy: 0.9333 - val_loss: 0.1741 - val_precision_29: 0.9086 - val_recall_29: 0.9634 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9450 - loss: 0.1411 - precision_29: 0.9449 - recall_29: 0.9457 - val_accuracy: 0.9158 - val_loss: 0.2155 - val_precision_29: 0.9679 - val_recall_29: 0.8599 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.1337 - precision_29: 0.9496 - recall_29: 0.9479 - val_accuracy: 0.9395 - val_loss: 0.1595 - val_precision_29: 0.9285 - val_recall_29: 0.9523 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1299 - precision_29: 0.9512 - recall_29: 0.9489 - val_accuracy: 0.9354 - val_loss: 0.1661 - val_precision_29: 0.9195 - val_recall_29: 0.9543 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9510 - loss: 0.1260 - precision_29: 0.9511 - recall_29: 0.9507 - val_accuracy: 0.9285 - val_loss: 0.2010 - val_precision_29: 0.8928 - val_recall_29: 0.9738 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1222 - precision_29: 0.9535 - recall_29: 0.9517 - val_accuracy: 0.9293 - val_loss: 0.1804 - val_precision_29: 0.9030 - val_recall_29: 0.9618 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9538 - loss: 0.1182 - precision_29: 0.9553 - recall_29: 0.9523 - val_accuracy: 0.9317 - val_loss: 0.1945 - val_precision_29: 0.9381 - val_recall_29: 0.9245 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1135 - precision_29: 0.9575 - recall_29: 0.9537 - val_accuracy: 0.9377 - val_loss: 0.1710 - val_precision_29: 0.9194 - val_recall_29: 0.9595 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.0986 - precision_29: 0.9618 - recall_29: 0.9615 - val_accuracy: 0.9419 - val_loss: 0.1626 - val_precision_29: 0.9251 - val_recall_29: 0.9615 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.0921 - precision_29: 0.9657 - recall_29: 0.9632 - val_accuracy: 0.9453 - val_loss: 0.1502 - val_precision_29: 0.9437 - val_recall_29: 0.9471 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9653 - loss: 0.0910 - precision_29: 0.9663 - recall_29: 0.9644 - val_accuracy: 0.9455 - val_loss: 0.1512 - val_precision_29: 0.9390 - val_recall_29: 0.9527 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0899 - precision_29: 0.9663 - recall_29: 0.9670 - val_accuracy: 0.9421 - val_loss: 0.1598 - val_precision_29: 0.9397 - val_recall_29: 0.9449 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.0813 - precision_29: 0.9698 - recall_29: 0.9681 - val_accuracy: 0.9439 - val_loss: 0.1600 - val_precision_29: 0.9374 - val_recall_29: 0.9513 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9679 - loss: 0.0846 - precision_29: 0.9681 - recall_29: 0.9676 - val_accuracy: 0.9456 - val_loss: 0.1574 - val_precision_29: 0.9424 - val_recall_29: 0.9493 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.8548 - loss: 0.3332 - precision_30: 0.8489 - recall_30: 0.8640 - val_accuracy: 0.9180 - val_loss: 0.2153 - val_precision_30: 0.9512 - val_recall_30: 0.8812 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9286 - loss: 0.1822 - precision_30: 0.9280 - recall_30: 0.9292 - val_accuracy: 0.9262 - val_loss: 0.1855 - val_precision_30: 0.9622 - val_recall_30: 0.8872 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.1560 - precision_30: 0.9391 - recall_30: 0.9378 - val_accuracy: 0.9137 - val_loss: 0.2149 - val_precision_30: 0.9722 - val_recall_30: 0.8516 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.1416 - precision_30: 0.9447 - recall_30: 0.9444 - val_accuracy: 0.9342 - val_loss: 0.1708 - val_precision_30: 0.9247 - val_recall_30: 0.9455 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1258 - precision_30: 0.9519 - recall_30: 0.9509 - val_accuracy: 0.8900 - val_loss: 0.2814 - val_precision_30: 0.9809 - val_recall_30: 0.7955 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9545 - loss: 0.1197 - precision_30: 0.9552 - recall_30: 0.9534 - val_accuracy: 0.8946 - val_loss: 0.3144 - val_precision_30: 0.8334 - val_recall_30: 0.9863 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.1077 - precision_30: 0.9591 - recall_30: 0.9590 - val_accuracy: 0.9204 - val_loss: 0.2472 - val_precision_30: 0.8956 - val_recall_30: 0.9518 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9607 - loss: 0.1013 - precision_30: 0.9607 - recall_30: 0.9606 - val_accuracy: 0.9454 - val_loss: 0.1480 - val_precision_30: 0.9611 - val_recall_30: 0.9284 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9649 - loss: 0.0923 - precision_30: 0.9652 - recall_30: 0.9644 - val_accuracy: 0.9467 - val_loss: 0.1454 - val_precision_30: 0.9452 - val_recall_30: 0.9483 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.0890 - precision_30: 0.9655 - recall_30: 0.9673 - val_accuracy: 0.9373 - val_loss: 0.1771 - val_precision_30: 0.9751 - val_recall_30: 0.8975 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.0809 - precision_30: 0.9703 - recall_30: 0.9674 - val_accuracy: 0.9465 - val_loss: 0.1577 - val_precision_30: 0.9581 - val_recall_30: 0.9338 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.0740 - precision_30: 0.9726 - recall_30: 0.9717 - val_accuracy: 0.9457 - val_loss: 0.1653 - val_precision_30: 0.9396 - val_recall_30: 0.9526 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.0724 - precision_30: 0.9732 - recall_30: 0.9709 - val_accuracy: 0.9439 - val_loss: 0.1576 - val_precision_30: 0.9494 - val_recall_30: 0.9378 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9746 - loss: 0.0670 - precision_30: 0.9747 - recall_30: 0.9748 - val_accuracy: 0.9433 - val_loss: 0.1727 - val_precision_30: 0.9268 - val_recall_30: 0.9625 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9825 - loss: 0.0505 - precision_30: 0.9816 - recall_30: 0.9836 - val_accuracy: 0.9498 - val_loss: 0.1588 - val_precision_30: 0.9374 - val_recall_30: 0.9639 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0380 - precision_30: 0.9882 - recall_30: 0.9868 - val_accuracy: 0.9517 - val_loss: 0.1509 - val_precision_30: 0.9510 - val_recall_30: 0.9523 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0349 - precision_30: 0.9885 - recall_30: 0.9883 - val_accuracy: 0.9518 - val_loss: 0.1554 - val_precision_30: 0.9598 - val_recall_30: 0.9431 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0316 - precision_30: 0.9885 - recall_30: 0.9895 - val_accuracy: 0.9503 - val_loss: 0.1758 - val_precision_30: 0.9352 - val_recall_30: 0.9675 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0280 - precision_30: 0.9913 - recall_30: 0.9909 - val_accuracy: 0.9513 - val_loss: 0.1648 - val_precision_30: 0.9438 - val_recall_30: 0.9596 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.8574 - loss: 0.3335 - precision_31: 0.8511 - recall_31: 0.8669 - val_accuracy: 0.8243 - val_loss: 0.4941 - val_precision_31: 0.7437 - val_recall_31: 0.9895 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.1704 - precision_31: 0.9331 - recall_31: 0.9332 - val_accuracy: 0.9256 - val_loss: 0.1993 - val_precision_31: 0.9129 - val_recall_31: 0.9409 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9441 - loss: 0.1427 - precision_31: 0.9445 - recall_31: 0.9427 - val_accuracy: 0.8432 - val_loss: 0.4069 - val_precision_31: 0.9831 - val_recall_31: 0.6983 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1230 - precision_31: 0.9537 - recall_31: 0.9519 - val_accuracy: 0.9357 - val_loss: 0.1704 - val_precision_31: 0.9118 - val_recall_31: 0.9646 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9571 - loss: 0.1131 - precision_31: 0.9585 - recall_31: 0.9557 - val_accuracy: 0.9132 - val_loss: 0.2307 - val_precision_31: 0.9659 - val_recall_31: 0.8565 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.0921 - precision_31: 0.9675 - recall_31: 0.9637 - val_accuracy: 0.9296 - val_loss: 0.1856 - val_precision_31: 0.9421 - val_recall_31: 0.9153 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.0876 - precision_31: 0.9674 - recall_31: 0.9656 - val_accuracy: 0.8929 - val_loss: 0.3510 - val_precision_31: 0.8289 - val_recall_31: 0.9900 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9727 - loss: 0.0734 - precision_31: 0.9733 - recall_31: 0.9724 - val_accuracy: 0.9500 - val_loss: 0.1503 - val_precision_31: 0.9513 - val_recall_31: 0.9486 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0702 - precision_31: 0.9744 - recall_31: 0.9714 - val_accuracy: 0.9546 - val_loss: 0.1328 - val_precision_31: 0.9541 - val_recall_31: 0.9551 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0560 - precision_31: 0.9807 - recall_31: 0.9797 - val_accuracy: 0.9319 - val_loss: 0.1937 - val_precision_31: 0.9333 - val_recall_31: 0.9304 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.0538 - precision_31: 0.9788 - recall_31: 0.9795 - val_accuracy: 0.9444 - val_loss: 0.1646 - val_precision_31: 0.9603 - val_recall_31: 0.9271 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0468 - precision_31: 0.9817 - recall_31: 0.9815 - val_accuracy: 0.9467 - val_loss: 0.1747 - val_precision_31: 0.9617 - val_recall_31: 0.9305 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0395 - precision_31: 0.9861 - recall_31: 0.9847 - val_accuracy: 0.9503 - val_loss: 0.1606 - val_precision_31: 0.9530 - val_recall_31: 0.9473 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0348 - precision_31: 0.9873 - recall_31: 0.9865 - val_accuracy: 0.9488 - val_loss: 0.1736 - val_precision_31: 0.9605 - val_recall_31: 0.9362 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0233 - precision_31: 0.9934 - recall_31: 0.9917 - val_accuracy: 0.9550 - val_loss: 0.1530 - val_precision_31: 0.9693 - val_recall_31: 0.9398 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0117 - precision_31: 0.9970 - recall_31: 0.9967 - val_accuracy: 0.9560 - val_loss: 0.1669 - val_precision_31: 0.9617 - val_recall_31: 0.9497 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0086 - precision_31: 0.9980 - recall_31: 0.9977 - val_accuracy: 0.9564 - val_loss: 0.1734 - val_precision_31: 0.9561 - val_recall_31: 0.9567 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0075 - precision_31: 0.9986 - recall_31: 0.9980 - val_accuracy: 0.9543 - val_loss: 0.1839 - val_precision_31: 0.9453 - val_recall_31: 0.9645 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0055 - precision_31: 0.9990 - recall_31: 0.9989 - val_accuracy: 0.9564 - val_loss: 0.1932 - val_precision_31: 0.9501 - val_recall_31: 0.9635 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "[1단계] Conv 레이어 최적화 결과:\n",
            "   conv_layers  filters  val_accuracy  test_accuracy\n",
            "0            1       16       0.93595        0.93415\n",
            "1            1       32       0.93865        0.93190\n",
            "2            1       64       0.93995        0.93065\n",
            "3            2       16       0.94460        0.93960\n",
            "4            2       32       0.95230        0.95040\n",
            "5            2       64       0.95735        0.95640\n",
            "6            3       16       0.94565        0.94665\n",
            "7            3       32       0.95180        0.94685\n",
            "8            3       64       0.95645        0.95375\n",
            "\n",
            "최적 조합: Conv 층 2.0개, 필터 64.0개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_dense_params = grid_search_dense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vwHbhOvjq2N",
        "outputId": "0c5ef51b-1b3f-4772-ba83-de7ec94208a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8526 - loss: 0.3407 - precision_56: 0.8449 - recall_56: 0.8648 - val_accuracy: 0.9175 - val_loss: 0.2091 - val_precision_56: 0.9299 - val_recall_56: 0.9028 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.1950 - precision_56: 0.9209 - recall_56: 0.9251 - val_accuracy: 0.9043 - val_loss: 0.2451 - val_precision_56: 0.8576 - val_recall_56: 0.9694 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9366 - loss: 0.1632 - precision_56: 0.9360 - recall_56: 0.9373 - val_accuracy: 0.9039 - val_loss: 0.2529 - val_precision_56: 0.8528 - val_recall_56: 0.9760 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1504 - precision_56: 0.9441 - recall_56: 0.9405 - val_accuracy: 0.9079 - val_loss: 0.2243 - val_precision_56: 0.9755 - val_recall_56: 0.8366 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1371 - precision_56: 0.9489 - recall_56: 0.9447 - val_accuracy: 0.9277 - val_loss: 0.1919 - val_precision_56: 0.9145 - val_recall_56: 0.9436 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1307 - precision_56: 0.9507 - recall_56: 0.9483 - val_accuracy: 0.9334 - val_loss: 0.1693 - val_precision_56: 0.9542 - val_recall_56: 0.9104 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9537 - loss: 0.1210 - precision_56: 0.9554 - recall_56: 0.9522 - val_accuracy: 0.9052 - val_loss: 0.2405 - val_precision_56: 0.8560 - val_recall_56: 0.9742 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9573 - loss: 0.1122 - precision_56: 0.9584 - recall_56: 0.9560 - val_accuracy: 0.9355 - val_loss: 0.1655 - val_precision_56: 0.9236 - val_recall_56: 0.9495 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.1050 - precision_56: 0.9616 - recall_56: 0.9594 - val_accuracy: 0.9376 - val_loss: 0.1687 - val_precision_56: 0.9279 - val_recall_56: 0.9489 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.0970 - precision_56: 0.9610 - recall_56: 0.9625 - val_accuracy: 0.9308 - val_loss: 0.1786 - val_precision_56: 0.9647 - val_recall_56: 0.8941 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.0910 - precision_56: 0.9651 - recall_56: 0.9637 - val_accuracy: 0.9338 - val_loss: 0.1871 - val_precision_56: 0.9141 - val_recall_56: 0.9575 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.0858 - precision_56: 0.9669 - recall_56: 0.9679 - val_accuracy: 0.9427 - val_loss: 0.1576 - val_precision_56: 0.9599 - val_recall_56: 0.9241 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.0828 - precision_56: 0.9695 - recall_56: 0.9682 - val_accuracy: 0.9142 - val_loss: 0.2541 - val_precision_56: 0.8662 - val_recall_56: 0.9796 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.0780 - precision_56: 0.9697 - recall_56: 0.9693 - val_accuracy: 0.9373 - val_loss: 0.1938 - val_precision_56: 0.9237 - val_recall_56: 0.9534 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0721 - precision_56: 0.9718 - recall_56: 0.9704 - val_accuracy: 0.9360 - val_loss: 0.2219 - val_precision_56: 0.9282 - val_recall_56: 0.9451 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0693 - precision_56: 0.9731 - recall_56: 0.9739 - val_accuracy: 0.9329 - val_loss: 0.1999 - val_precision_56: 0.9176 - val_recall_56: 0.9511 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0655 - precision_56: 0.9750 - recall_56: 0.9751 - val_accuracy: 0.8767 - val_loss: 0.5121 - val_precision_56: 0.8072 - val_recall_56: 0.9897 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0509 - precision_56: 0.9805 - recall_56: 0.9817 - val_accuracy: 0.9464 - val_loss: 0.1726 - val_precision_56: 0.9312 - val_recall_56: 0.9641 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.0415 - precision_56: 0.9843 - recall_56: 0.9859 - val_accuracy: 0.9503 - val_loss: 0.1647 - val_precision_56: 0.9609 - val_recall_56: 0.9388 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0380 - precision_56: 0.9862 - recall_56: 0.9866 - val_accuracy: 0.9488 - val_loss: 0.1705 - val_precision_56: 0.9541 - val_recall_56: 0.9430 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.3405 - precision_57: 0.8419 - recall_57: 0.8633 - val_accuracy: 0.8845 - val_loss: 0.2655 - val_precision_57: 0.9742 - val_recall_57: 0.7897 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9276 - loss: 0.1834 - precision_57: 0.9258 - recall_57: 0.9290 - val_accuracy: 0.9268 - val_loss: 0.1910 - val_precision_57: 0.9519 - val_recall_57: 0.8989 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.1573 - precision_57: 0.9370 - recall_57: 0.9360 - val_accuracy: 0.9247 - val_loss: 0.1946 - val_precision_57: 0.8895 - val_recall_57: 0.9699 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1344 - precision_57: 0.9477 - recall_57: 0.9490 - val_accuracy: 0.9248 - val_loss: 0.1868 - val_precision_57: 0.9642 - val_recall_57: 0.8823 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1223 - precision_57: 0.9546 - recall_57: 0.9516 - val_accuracy: 0.9396 - val_loss: 0.1622 - val_precision_57: 0.9226 - val_recall_57: 0.9596 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.1091 - precision_57: 0.9591 - recall_57: 0.9571 - val_accuracy: 0.9368 - val_loss: 0.1677 - val_precision_57: 0.9116 - val_recall_57: 0.9674 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.0968 - precision_57: 0.9636 - recall_57: 0.9635 - val_accuracy: 0.9448 - val_loss: 0.1533 - val_precision_57: 0.9333 - val_recall_57: 0.9579 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.0873 - precision_57: 0.9662 - recall_57: 0.9666 - val_accuracy: 0.9247 - val_loss: 0.2364 - val_precision_57: 0.8825 - val_recall_57: 0.9796 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9691 - loss: 0.0815 - precision_57: 0.9684 - recall_57: 0.9700 - val_accuracy: 0.9324 - val_loss: 0.1933 - val_precision_57: 0.8999 - val_recall_57: 0.9730 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9739 - loss: 0.0712 - precision_57: 0.9742 - recall_57: 0.9738 - val_accuracy: 0.9281 - val_loss: 0.2156 - val_precision_57: 0.9741 - val_recall_57: 0.8795 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0660 - precision_57: 0.9754 - recall_57: 0.9737 - val_accuracy: 0.9236 - val_loss: 0.2345 - val_precision_57: 0.9689 - val_recall_57: 0.8752 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0621 - precision_57: 0.9770 - recall_57: 0.9756 - val_accuracy: 0.9385 - val_loss: 0.1702 - val_precision_57: 0.9578 - val_recall_57: 0.9175 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0461 - precision_57: 0.9837 - recall_57: 0.9821 - val_accuracy: 0.9441 - val_loss: 0.1844 - val_precision_57: 0.9194 - val_recall_57: 0.9735 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0351 - precision_57: 0.9889 - recall_57: 0.9878 - val_accuracy: 0.9520 - val_loss: 0.1466 - val_precision_57: 0.9470 - val_recall_57: 0.9577 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0331 - precision_57: 0.9884 - recall_57: 0.9890 - val_accuracy: 0.9503 - val_loss: 0.1532 - val_precision_57: 0.9401 - val_recall_57: 0.9619 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0294 - precision_57: 0.9908 - recall_57: 0.9901 - val_accuracy: 0.9527 - val_loss: 0.1502 - val_precision_57: 0.9587 - val_recall_57: 0.9461 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0252 - precision_57: 0.9914 - recall_57: 0.9921 - val_accuracy: 0.9503 - val_loss: 0.1591 - val_precision_57: 0.9557 - val_recall_57: 0.9442 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0256 - precision_57: 0.9916 - recall_57: 0.9919 - val_accuracy: 0.9485 - val_loss: 0.1882 - val_precision_57: 0.9305 - val_recall_57: 0.9694 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0229 - precision_57: 0.9932 - recall_57: 0.9919 - val_accuracy: 0.9484 - val_loss: 0.1816 - val_precision_57: 0.9343 - val_recall_57: 0.9646 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0195 - precision_57: 0.9947 - recall_57: 0.9933 - val_accuracy: 0.9516 - val_loss: 0.1707 - val_precision_57: 0.9528 - val_recall_57: 0.9501 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.8593 - loss: 0.3319 - precision_58: 0.8514 - recall_58: 0.8722 - val_accuracy: 0.9296 - val_loss: 0.1831 - val_precision_58: 0.9472 - val_recall_58: 0.9098 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.1703 - precision_58: 0.9309 - recall_58: 0.9335 - val_accuracy: 0.9287 - val_loss: 0.1826 - val_precision_58: 0.9010 - val_recall_58: 0.9631 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9457 - loss: 0.1406 - precision_58: 0.9459 - recall_58: 0.9450 - val_accuracy: 0.9381 - val_loss: 0.1606 - val_precision_58: 0.9590 - val_recall_58: 0.9152 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1244 - precision_58: 0.9515 - recall_58: 0.9519 - val_accuracy: 0.9140 - val_loss: 0.2239 - val_precision_58: 0.9670 - val_recall_58: 0.8571 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1074 - precision_58: 0.9591 - recall_58: 0.9591 - val_accuracy: 0.9230 - val_loss: 0.2054 - val_precision_58: 0.9743 - val_recall_58: 0.8687 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.0940 - precision_58: 0.9648 - recall_58: 0.9630 - val_accuracy: 0.8644 - val_loss: 0.3388 - val_precision_58: 0.9853 - val_recall_58: 0.7395 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.0790 - precision_58: 0.9708 - recall_58: 0.9695 - val_accuracy: 0.9290 - val_loss: 0.2363 - val_precision_58: 0.8927 - val_recall_58: 0.9750 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9728 - loss: 0.0716 - precision_58: 0.9736 - recall_58: 0.9715 - val_accuracy: 0.9349 - val_loss: 0.1883 - val_precision_58: 0.9535 - val_recall_58: 0.9144 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0489 - precision_58: 0.9829 - recall_58: 0.9830 - val_accuracy: 0.9373 - val_loss: 0.1968 - val_precision_58: 0.9050 - val_recall_58: 0.9772 - learning_rate: 2.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0383 - precision_58: 0.9882 - recall_58: 0.9873 - val_accuracy: 0.9520 - val_loss: 0.1514 - val_precision_58: 0.9385 - val_recall_58: 0.9674 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0320 - precision_58: 0.9898 - recall_58: 0.9900 - val_accuracy: 0.9519 - val_loss: 0.1446 - val_precision_58: 0.9647 - val_recall_58: 0.9381 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0271 - precision_58: 0.9914 - recall_58: 0.9929 - val_accuracy: 0.9517 - val_loss: 0.1641 - val_precision_58: 0.9414 - val_recall_58: 0.9633 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0241 - precision_58: 0.9928 - recall_58: 0.9926 - val_accuracy: 0.9506 - val_loss: 0.1796 - val_precision_58: 0.9344 - val_recall_58: 0.9693 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0202 - precision_58: 0.9938 - recall_58: 0.9942 - val_accuracy: 0.9483 - val_loss: 0.1747 - val_precision_58: 0.9309 - val_recall_58: 0.9685 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0181 - precision_58: 0.9946 - recall_58: 0.9950 - val_accuracy: 0.9488 - val_loss: 0.1755 - val_precision_58: 0.9653 - val_recall_58: 0.9310 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0158 - precision_58: 0.9951 - recall_58: 0.9956 - val_accuracy: 0.9353 - val_loss: 0.2094 - val_precision_58: 0.9781 - val_recall_58: 0.8904 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0129 - precision_58: 0.9965 - recall_58: 0.9962 - val_accuracy: 0.9534 - val_loss: 0.1638 - val_precision_58: 0.9550 - val_recall_58: 0.9515 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0116 - precision_58: 0.9965 - recall_58: 0.9972 - val_accuracy: 0.9540 - val_loss: 0.1754 - val_precision_58: 0.9497 - val_recall_58: 0.9587 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0105 - precision_58: 0.9973 - recall_58: 0.9967 - val_accuracy: 0.9519 - val_loss: 0.1776 - val_precision_58: 0.9609 - val_recall_58: 0.9421 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0100 - precision_58: 0.9972 - recall_58: 0.9976 - val_accuracy: 0.9528 - val_loss: 0.1786 - val_precision_58: 0.9427 - val_recall_58: 0.9642 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8271 - loss: 0.3862 - precision_59: 0.8114 - recall_59: 0.8557 - val_accuracy: 0.8848 - val_loss: 0.2756 - val_precision_59: 0.9104 - val_recall_59: 0.8535 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9152 - loss: 0.2126 - precision_59: 0.9144 - recall_59: 0.9164 - val_accuracy: 0.8997 - val_loss: 0.2657 - val_precision_59: 0.8485 - val_recall_59: 0.9731 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1814 - precision_59: 0.9291 - recall_59: 0.9300 - val_accuracy: 0.8109 - val_loss: 0.4608 - val_precision_59: 0.9864 - val_recall_59: 0.6303 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9368 - loss: 0.1655 - precision_59: 0.9364 - recall_59: 0.9364 - val_accuracy: 0.8925 - val_loss: 0.2715 - val_precision_59: 0.9725 - val_recall_59: 0.8078 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.1496 - precision_59: 0.9443 - recall_59: 0.9425 - val_accuracy: 0.9433 - val_loss: 0.1519 - val_precision_59: 0.9532 - val_recall_59: 0.9324 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9499 - loss: 0.1361 - precision_59: 0.9496 - recall_59: 0.9504 - val_accuracy: 0.8145 - val_loss: 0.4502 - val_precision_59: 0.9926 - val_recall_59: 0.6335 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1292 - precision_59: 0.9518 - recall_59: 0.9512 - val_accuracy: 0.9279 - val_loss: 0.1955 - val_precision_59: 0.9501 - val_recall_59: 0.9031 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.1181 - precision_59: 0.9560 - recall_59: 0.9549 - val_accuracy: 0.9435 - val_loss: 0.1547 - val_precision_59: 0.9592 - val_recall_59: 0.9264 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9596 - loss: 0.1109 - precision_59: 0.9587 - recall_59: 0.9601 - val_accuracy: 0.9396 - val_loss: 0.1664 - val_precision_59: 0.9567 - val_recall_59: 0.9209 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.1044 - precision_59: 0.9603 - recall_59: 0.9623 - val_accuracy: 0.9430 - val_loss: 0.1555 - val_precision_59: 0.9270 - val_recall_59: 0.9616 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0847 - precision_59: 0.9693 - recall_59: 0.9705 - val_accuracy: 0.9508 - val_loss: 0.1357 - val_precision_59: 0.9479 - val_recall_59: 0.9540 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0723 - precision_59: 0.9755 - recall_59: 0.9744 - val_accuracy: 0.9511 - val_loss: 0.1492 - val_precision_59: 0.9464 - val_recall_59: 0.9563 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.0666 - precision_59: 0.9762 - recall_59: 0.9785 - val_accuracy: 0.9481 - val_loss: 0.1486 - val_precision_59: 0.9360 - val_recall_59: 0.9619 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9783 - loss: 0.0642 - precision_59: 0.9775 - recall_59: 0.9795 - val_accuracy: 0.9479 - val_loss: 0.1617 - val_precision_59: 0.9321 - val_recall_59: 0.9661 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0601 - precision_59: 0.9794 - recall_59: 0.9792 - val_accuracy: 0.9456 - val_loss: 0.1603 - val_precision_59: 0.9641 - val_recall_59: 0.9255 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0567 - precision_59: 0.9799 - recall_59: 0.9809 - val_accuracy: 0.9491 - val_loss: 0.1555 - val_precision_59: 0.9582 - val_recall_59: 0.9390 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0511 - precision_59: 0.9811 - recall_59: 0.9854 - val_accuracy: 0.9492 - val_loss: 0.1604 - val_precision_59: 0.9581 - val_recall_59: 0.9395 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9825 - loss: 0.0502 - precision_59: 0.9820 - recall_59: 0.9831 - val_accuracy: 0.9493 - val_loss: 0.1609 - val_precision_59: 0.9532 - val_recall_59: 0.9450 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0499 - precision_59: 0.9827 - recall_59: 0.9837 - val_accuracy: 0.9498 - val_loss: 0.1614 - val_precision_59: 0.9460 - val_recall_59: 0.9539 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0458 - precision_59: 0.9840 - recall_59: 0.9862 - val_accuracy: 0.9496 - val_loss: 0.1645 - val_precision_59: 0.9595 - val_recall_59: 0.9388 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8195 - loss: 0.3997 - precision_60: 0.8111 - recall_60: 0.8317 - val_accuracy: 0.9212 - val_loss: 0.1999 - val_precision_60: 0.9106 - val_recall_60: 0.9341 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.1998 - precision_60: 0.9200 - recall_60: 0.9218 - val_accuracy: 0.9348 - val_loss: 0.1733 - val_precision_60: 0.9553 - val_recall_60: 0.9123 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 0.1668 - precision_60: 0.9367 - recall_60: 0.9353 - val_accuracy: 0.9348 - val_loss: 0.1641 - val_precision_60: 0.9542 - val_recall_60: 0.9132 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1463 - precision_60: 0.9445 - recall_60: 0.9428 - val_accuracy: 0.9394 - val_loss: 0.1613 - val_precision_60: 0.9554 - val_recall_60: 0.9218 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1286 - precision_60: 0.9519 - recall_60: 0.9511 - val_accuracy: 0.6838 - val_loss: 0.8745 - val_precision_60: 0.9943 - val_recall_60: 0.3693 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1206 - precision_60: 0.9562 - recall_60: 0.9527 - val_accuracy: 0.9429 - val_loss: 0.1521 - val_precision_60: 0.9464 - val_recall_60: 0.9389 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1105 - precision_60: 0.9591 - recall_60: 0.9576 - val_accuracy: 0.9302 - val_loss: 0.1777 - val_precision_60: 0.9731 - val_recall_60: 0.8847 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9627 - loss: 0.1010 - precision_60: 0.9625 - recall_60: 0.9628 - val_accuracy: 0.9441 - val_loss: 0.1489 - val_precision_60: 0.9372 - val_recall_60: 0.9521 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9664 - loss: 0.0895 - precision_60: 0.9659 - recall_60: 0.9677 - val_accuracy: 0.9312 - val_loss: 0.1868 - val_precision_60: 0.9035 - val_recall_60: 0.9655 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.0825 - precision_60: 0.9700 - recall_60: 0.9675 - val_accuracy: 0.9201 - val_loss: 0.2174 - val_precision_60: 0.9791 - val_recall_60: 0.8585 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0701 - precision_60: 0.9743 - recall_60: 0.9732 - val_accuracy: 0.9442 - val_loss: 0.1635 - val_precision_60: 0.9417 - val_recall_60: 0.9471 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.0734 - precision_60: 0.9717 - recall_60: 0.9740 - val_accuracy: 0.9390 - val_loss: 0.1839 - val_precision_60: 0.9272 - val_recall_60: 0.9528 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0644 - precision_60: 0.9752 - recall_60: 0.9761 - val_accuracy: 0.9431 - val_loss: 0.1662 - val_precision_60: 0.9334 - val_recall_60: 0.9543 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0475 - precision_60: 0.9805 - recall_60: 0.9851 - val_accuracy: 0.9538 - val_loss: 0.1473 - val_precision_60: 0.9550 - val_recall_60: 0.9523 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0366 - precision_60: 0.9866 - recall_60: 0.9878 - val_accuracy: 0.9516 - val_loss: 0.1607 - val_precision_60: 0.9541 - val_recall_60: 0.9488 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0319 - precision_60: 0.9893 - recall_60: 0.9892 - val_accuracy: 0.9434 - val_loss: 0.1951 - val_precision_60: 0.9749 - val_recall_60: 0.9101 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0278 - precision_60: 0.9905 - recall_60: 0.9905 - val_accuracy: 0.9500 - val_loss: 0.1774 - val_precision_60: 0.9669 - val_recall_60: 0.9320 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0259 - precision_60: 0.9910 - recall_60: 0.9914 - val_accuracy: 0.9534 - val_loss: 0.1754 - val_precision_60: 0.9551 - val_recall_60: 0.9514 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0234 - precision_60: 0.9920 - recall_60: 0.9918 - val_accuracy: 0.9487 - val_loss: 0.1887 - val_precision_60: 0.9669 - val_recall_60: 0.9292 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0226 - precision_60: 0.9914 - recall_60: 0.9930 - val_accuracy: 0.9539 - val_loss: 0.1797 - val_precision_60: 0.9575 - val_recall_60: 0.9499 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8424 - loss: 0.3584 - precision_61: 0.8363 - recall_61: 0.8519 - val_accuracy: 0.8753 - val_loss: 0.2914 - val_precision_61: 0.9684 - val_recall_61: 0.7759 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.1899 - precision_61: 0.9265 - recall_61: 0.9244 - val_accuracy: 0.9204 - val_loss: 0.2005 - val_precision_61: 0.9320 - val_recall_61: 0.9068 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9405 - loss: 0.1560 - precision_61: 0.9414 - recall_61: 0.9400 - val_accuracy: 0.9268 - val_loss: 0.1879 - val_precision_61: 0.9313 - val_recall_61: 0.9214 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.1371 - precision_61: 0.9475 - recall_61: 0.9464 - val_accuracy: 0.8285 - val_loss: 0.4726 - val_precision_61: 0.9836 - val_recall_61: 0.6679 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1190 - precision_61: 0.9545 - recall_61: 0.9545 - val_accuracy: 0.8953 - val_loss: 0.2865 - val_precision_61: 0.9808 - val_recall_61: 0.8064 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9605 - loss: 0.1033 - precision_61: 0.9606 - recall_61: 0.9608 - val_accuracy: 0.9002 - val_loss: 0.2647 - val_precision_61: 0.8434 - val_recall_61: 0.9828 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.0939 - precision_61: 0.9646 - recall_61: 0.9646 - val_accuracy: 0.9446 - val_loss: 0.1471 - val_precision_61: 0.9508 - val_recall_61: 0.9378 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0820 - precision_61: 0.9705 - recall_61: 0.9691 - val_accuracy: 0.8758 - val_loss: 0.3708 - val_precision_61: 0.9894 - val_recall_61: 0.7596 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0718 - precision_61: 0.9719 - recall_61: 0.9740 - val_accuracy: 0.9413 - val_loss: 0.1738 - val_precision_61: 0.9426 - val_recall_61: 0.9398 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9762 - loss: 0.0629 - precision_61: 0.9763 - recall_61: 0.9758 - val_accuracy: 0.9309 - val_loss: 0.1972 - val_precision_61: 0.9742 - val_recall_61: 0.8851 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9788 - loss: 0.0569 - precision_61: 0.9784 - recall_61: 0.9789 - val_accuracy: 0.9236 - val_loss: 0.2269 - val_precision_61: 0.9624 - val_recall_61: 0.8815 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 0.0531 - precision_61: 0.9804 - recall_61: 0.9795 - val_accuracy: 0.9470 - val_loss: 0.1717 - val_precision_61: 0.9525 - val_recall_61: 0.9410 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0367 - precision_61: 0.9872 - recall_61: 0.9869 - val_accuracy: 0.9531 - val_loss: 0.1593 - val_precision_61: 0.9588 - val_recall_61: 0.9468 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0238 - precision_61: 0.9913 - recall_61: 0.9927 - val_accuracy: 0.9493 - val_loss: 0.1683 - val_precision_61: 0.9372 - val_recall_61: 0.9632 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0208 - precision_61: 0.9920 - recall_61: 0.9938 - val_accuracy: 0.9524 - val_loss: 0.1781 - val_precision_61: 0.9482 - val_recall_61: 0.9569 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0172 - precision_61: 0.9944 - recall_61: 0.9937 - val_accuracy: 0.9426 - val_loss: 0.2217 - val_precision_61: 0.9748 - val_recall_61: 0.9086 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0153 - precision_61: 0.9940 - recall_61: 0.9949 - val_accuracy: 0.9524 - val_loss: 0.1960 - val_precision_61: 0.9532 - val_recall_61: 0.9514 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7644 - loss: 0.4782 - precision_62: 0.7601 - recall_62: 0.7746 - val_accuracy: 0.8500 - val_loss: 0.3415 - val_precision_62: 0.9442 - val_recall_62: 0.7437 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2398 - precision_62: 0.9060 - recall_62: 0.9078 - val_accuracy: 0.9109 - val_loss: 0.2279 - val_precision_62: 0.9331 - val_recall_62: 0.8851 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.1975 - precision_62: 0.9256 - recall_62: 0.9218 - val_accuracy: 0.8996 - val_loss: 0.2452 - val_precision_62: 0.9613 - val_recall_62: 0.8325 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9322 - loss: 0.1769 - precision_62: 0.9325 - recall_62: 0.9318 - val_accuracy: 0.9303 - val_loss: 0.1753 - val_precision_62: 0.9244 - val_recall_62: 0.9372 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1608 - precision_62: 0.9394 - recall_62: 0.9385 - val_accuracy: 0.9293 - val_loss: 0.1827 - val_precision_62: 0.9693 - val_recall_62: 0.8866 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1510 - precision_62: 0.9455 - recall_62: 0.9417 - val_accuracy: 0.7719 - val_loss: 0.5915 - val_precision_62: 0.9888 - val_recall_62: 0.5497 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.1420 - precision_62: 0.9480 - recall_62: 0.9455 - val_accuracy: 0.9302 - val_loss: 0.1881 - val_precision_62: 0.8988 - val_recall_62: 0.9695 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1312 - precision_62: 0.9507 - recall_62: 0.9513 - val_accuracy: 0.9011 - val_loss: 0.2471 - val_precision_62: 0.8477 - val_recall_62: 0.9777 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.1224 - precision_62: 0.9545 - recall_62: 0.9542 - val_accuracy: 0.9443 - val_loss: 0.1484 - val_precision_62: 0.9361 - val_recall_62: 0.9537 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.1139 - precision_62: 0.9577 - recall_62: 0.9577 - val_accuracy: 0.9125 - val_loss: 0.2279 - val_precision_62: 0.9685 - val_recall_62: 0.8526 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 0.1067 - precision_62: 0.9606 - recall_62: 0.9615 - val_accuracy: 0.9244 - val_loss: 0.2149 - val_precision_62: 0.8884 - val_recall_62: 0.9706 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.1040 - precision_62: 0.9626 - recall_62: 0.9618 - val_accuracy: 0.9294 - val_loss: 0.2007 - val_precision_62: 0.9729 - val_recall_62: 0.8834 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.0954 - precision_62: 0.9647 - recall_62: 0.9649 - val_accuracy: 0.9422 - val_loss: 0.1605 - val_precision_62: 0.9236 - val_recall_62: 0.9641 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9659 - loss: 0.0938 - precision_62: 0.9662 - recall_62: 0.9657 - val_accuracy: 0.9432 - val_loss: 0.1634 - val_precision_62: 0.9322 - val_recall_62: 0.9559 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0772 - precision_62: 0.9698 - recall_62: 0.9754 - val_accuracy: 0.9489 - val_loss: 0.1504 - val_precision_62: 0.9505 - val_recall_62: 0.9471 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0606 - precision_62: 0.9791 - recall_62: 0.9795 - val_accuracy: 0.9442 - val_loss: 0.1687 - val_precision_62: 0.9291 - val_recall_62: 0.9619 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0570 - precision_62: 0.9806 - recall_62: 0.9817 - val_accuracy: 0.9264 - val_loss: 0.2382 - val_precision_62: 0.9808 - val_recall_62: 0.8697 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0559 - precision_62: 0.9804 - recall_62: 0.9818 - val_accuracy: 0.9498 - val_loss: 0.1606 - val_precision_62: 0.9466 - val_recall_62: 0.9532 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0541 - precision_62: 0.9803 - recall_62: 0.9835 - val_accuracy: 0.9494 - val_loss: 0.1643 - val_precision_62: 0.9504 - val_recall_62: 0.9483 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8180 - loss: 0.4023 - precision_63: 0.8073 - recall_63: 0.8388 - val_accuracy: 0.8184 - val_loss: 0.3973 - val_precision_63: 0.9836 - val_recall_63: 0.6474 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9156 - loss: 0.2145 - precision_63: 0.9150 - recall_63: 0.9166 - val_accuracy: 0.8687 - val_loss: 0.3713 - val_precision_63: 0.8034 - val_recall_63: 0.9759 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.1790 - precision_63: 0.9340 - recall_63: 0.9300 - val_accuracy: 0.8981 - val_loss: 0.2647 - val_precision_63: 0.8405 - val_recall_63: 0.9825 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.1629 - precision_63: 0.9365 - recall_63: 0.9357 - val_accuracy: 0.9257 - val_loss: 0.1850 - val_precision_63: 0.9259 - val_recall_63: 0.9253 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.1444 - precision_63: 0.9450 - recall_63: 0.9429 - val_accuracy: 0.9364 - val_loss: 0.1632 - val_precision_63: 0.9501 - val_recall_63: 0.9212 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1345 - precision_63: 0.9491 - recall_63: 0.9487 - val_accuracy: 0.9382 - val_loss: 0.1627 - val_precision_63: 0.9503 - val_recall_63: 0.9247 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1238 - precision_63: 0.9531 - recall_63: 0.9555 - val_accuracy: 0.9236 - val_loss: 0.2065 - val_precision_63: 0.8854 - val_recall_63: 0.9731 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1125 - precision_63: 0.9595 - recall_63: 0.9580 - val_accuracy: 0.9430 - val_loss: 0.1526 - val_precision_63: 0.9550 - val_recall_63: 0.9298 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9624 - loss: 0.1010 - precision_63: 0.9625 - recall_63: 0.9624 - val_accuracy: 0.9301 - val_loss: 0.1860 - val_precision_63: 0.8962 - val_recall_63: 0.9729 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.0957 - precision_63: 0.9640 - recall_63: 0.9636 - val_accuracy: 0.9240 - val_loss: 0.2297 - val_precision_63: 0.8936 - val_recall_63: 0.9626 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.0862 - precision_63: 0.9675 - recall_63: 0.9683 - val_accuracy: 0.9353 - val_loss: 0.1737 - val_precision_63: 0.9603 - val_recall_63: 0.9080 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.0812 - precision_63: 0.9698 - recall_63: 0.9712 - val_accuracy: 0.9467 - val_loss: 0.1540 - val_precision_63: 0.9483 - val_recall_63: 0.9449 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0766 - precision_63: 0.9715 - recall_63: 0.9740 - val_accuracy: 0.9323 - val_loss: 0.1956 - val_precision_63: 0.9614 - val_recall_63: 0.9007 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9802 - loss: 0.0588 - precision_63: 0.9789 - recall_63: 0.9818 - val_accuracy: 0.9487 - val_loss: 0.1636 - val_precision_63: 0.9337 - val_recall_63: 0.9660 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0435 - precision_63: 0.9850 - recall_63: 0.9863 - val_accuracy: 0.9455 - val_loss: 0.1927 - val_precision_63: 0.9223 - val_recall_63: 0.9728 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0392 - precision_63: 0.9858 - recall_63: 0.9880 - val_accuracy: 0.9515 - val_loss: 0.1675 - val_precision_63: 0.9582 - val_recall_63: 0.9442 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0343 - precision_63: 0.9869 - recall_63: 0.9898 - val_accuracy: 0.9480 - val_loss: 0.1857 - val_precision_63: 0.9342 - val_recall_63: 0.9638 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0347 - precision_63: 0.9868 - recall_63: 0.9899 - val_accuracy: 0.9515 - val_loss: 0.1812 - val_precision_63: 0.9555 - val_recall_63: 0.9471 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8313 - loss: 0.3792 - precision_64: 0.8240 - recall_64: 0.8417 - val_accuracy: 0.8428 - val_loss: 0.3689 - val_precision_64: 0.9518 - val_recall_64: 0.7218 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9189 - loss: 0.2050 - precision_64: 0.9181 - recall_64: 0.9199 - val_accuracy: 0.9191 - val_loss: 0.2171 - val_precision_64: 0.9009 - val_recall_64: 0.9418 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.1672 - precision_64: 0.9362 - recall_64: 0.9327 - val_accuracy: 0.8932 - val_loss: 0.3056 - val_precision_64: 0.8369 - val_recall_64: 0.9767 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1443 - precision_64: 0.9456 - recall_64: 0.9430 - val_accuracy: 0.8796 - val_loss: 0.2755 - val_precision_64: 0.9792 - val_recall_64: 0.7756 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.1331 - precision_64: 0.9521 - recall_64: 0.9474 - val_accuracy: 0.9329 - val_loss: 0.1830 - val_precision_64: 0.9643 - val_recall_64: 0.8989 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1127 - precision_64: 0.9582 - recall_64: 0.9572 - val_accuracy: 0.9391 - val_loss: 0.1597 - val_precision_64: 0.9375 - val_recall_64: 0.9408 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9609 - loss: 0.1045 - precision_64: 0.9603 - recall_64: 0.9615 - val_accuracy: 0.8990 - val_loss: 0.3048 - val_precision_64: 0.8407 - val_recall_64: 0.9845 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.0927 - precision_64: 0.9656 - recall_64: 0.9638 - val_accuracy: 0.9409 - val_loss: 0.1672 - val_precision_64: 0.9663 - val_recall_64: 0.9134 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9691 - loss: 0.0829 - precision_64: 0.9691 - recall_64: 0.9690 - val_accuracy: 0.8917 - val_loss: 0.3263 - val_precision_64: 0.9865 - val_recall_64: 0.7942 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 0.0742 - precision_64: 0.9744 - recall_64: 0.9729 - val_accuracy: 0.9410 - val_loss: 0.1655 - val_precision_64: 0.9477 - val_recall_64: 0.9335 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0673 - precision_64: 0.9750 - recall_64: 0.9748 - val_accuracy: 0.9442 - val_loss: 0.1576 - val_precision_64: 0.9370 - val_recall_64: 0.9524 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0645 - precision_64: 0.9757 - recall_64: 0.9763 - val_accuracy: 0.8953 - val_loss: 0.3571 - val_precision_64: 0.8329 - val_recall_64: 0.9888 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0576 - precision_64: 0.9775 - recall_64: 0.9797 - val_accuracy: 0.9316 - val_loss: 0.2088 - val_precision_64: 0.9619 - val_recall_64: 0.8987 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0494 - precision_64: 0.9812 - recall_64: 0.9823 - val_accuracy: 0.9344 - val_loss: 0.2066 - val_precision_64: 0.9452 - val_recall_64: 0.9221 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0485 - precision_64: 0.9813 - recall_64: 0.9822 - val_accuracy: 0.9445 - val_loss: 0.1864 - val_precision_64: 0.9603 - val_recall_64: 0.9272 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0443 - precision_64: 0.9843 - recall_64: 0.9834 - val_accuracy: 0.8973 - val_loss: 0.3543 - val_precision_64: 0.9830 - val_recall_64: 0.8085 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0305 - precision_64: 0.9883 - recall_64: 0.9901 - val_accuracy: 0.9521 - val_loss: 0.1810 - val_precision_64: 0.9577 - val_recall_64: 0.9460 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0207 - precision_64: 0.9926 - recall_64: 0.9939 - val_accuracy: 0.9500 - val_loss: 0.2011 - val_precision_64: 0.9386 - val_recall_64: 0.9630 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0172 - precision_64: 0.9944 - recall_64: 0.9940 - val_accuracy: 0.9513 - val_loss: 0.1959 - val_precision_64: 0.9505 - val_recall_64: 0.9521 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0163 - precision_64: 0.9937 - recall_64: 0.9945 - val_accuracy: 0.9520 - val_loss: 0.2070 - val_precision_64: 0.9553 - val_recall_64: 0.9485 - learning_rate: 2.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\n",
            "[2단계] Dense 레이어 최적화 결과:\n",
            "   dense_layers  neurons  val_accuracy  test_accuracy\n",
            "0             1       32       0.95030        0.94365\n",
            "1             1       64       0.95270        0.95275\n",
            "2             1      128       0.95400        0.95275\n",
            "3             2       32       0.95110        0.95005\n",
            "4             2       64       0.95390        0.95175\n",
            "5             2      128       0.95305        0.94615\n",
            "6             3       32       0.94975        0.94490\n",
            "7             3       64       0.95150        0.94310\n",
            "8             3      128       0.95210        0.94335\n",
            "\n",
            "최적 조합: Dense 층 1.0개, 뉴런 64.0개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 모델 구성\n",
        "final_model = build_model(\n",
        "    num_conv_layers=2,\n",
        "    conv_filters=64,\n",
        "    num_dense_layers=1,\n",
        "    dense_neurons=64,\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "\n",
        "# 모델 컴파일 및 훈련\n",
        "final_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "history_final = train_model(\n",
        "    final_model,\n",
        "    train_ds, val_ds,\n",
        "    train_batches, val_batches,\n",
        "    epochs=epochs_num,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# 테스트 평가\n",
        "y_pred_final = final_model.predict(test_ds)\n",
        "y_pred_final = np.round(y_pred_final).flatten()\n",
        "\n",
        "print('\\n[최종 모델] 테스트 결과')\n",
        "print(classification_report(y_true, y_pred_final, target_names=['FAKE', 'REAL'], digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDH8xT9Yjsff",
        "outputId": "346d26fe-470e-4b5d-a9e1-302c232f4994"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8633 - loss: 0.3217 - precision_74: 0.8530 - recall_74: 0.8786 - val_accuracy: 0.8608 - val_loss: 0.3660 - val_precision_74: 0.7905 - val_recall_74: 0.9815 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9322 - loss: 0.1742 - precision_74: 0.9311 - recall_74: 0.9326 - val_accuracy: 0.9007 - val_loss: 0.2463 - val_precision_74: 0.8453 - val_recall_74: 0.9806 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.1453 - precision_74: 0.9445 - recall_74: 0.9444 - val_accuracy: 0.7545 - val_loss: 0.5624 - val_precision_74: 0.9932 - val_recall_74: 0.5122 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1251 - precision_74: 0.9523 - recall_74: 0.9525 - val_accuracy: 0.9406 - val_loss: 0.1604 - val_precision_74: 0.9340 - val_recall_74: 0.9481 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1071 - precision_74: 0.9571 - recall_74: 0.9603 - val_accuracy: 0.9388 - val_loss: 0.1726 - val_precision_74: 0.9256 - val_recall_74: 0.9542 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.0934 - precision_74: 0.9639 - recall_74: 0.9653 - val_accuracy: 0.9420 - val_loss: 0.1645 - val_precision_74: 0.9308 - val_recall_74: 0.9548 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.0791 - precision_74: 0.9693 - recall_74: 0.9709 - val_accuracy: 0.9369 - val_loss: 0.1681 - val_precision_74: 0.9104 - val_recall_74: 0.9691 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.0719 - precision_74: 0.9710 - recall_74: 0.9733 - val_accuracy: 0.9295 - val_loss: 0.2212 - val_precision_74: 0.9045 - val_recall_74: 0.9603 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.0598 - precision_74: 0.9765 - recall_74: 0.9786 - val_accuracy: 0.9446 - val_loss: 0.1709 - val_precision_74: 0.9240 - val_recall_74: 0.9689 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0411 - precision_74: 0.9845 - recall_74: 0.9872 - val_accuracy: 0.9560 - val_loss: 0.1306 - val_precision_74: 0.9688 - val_recall_74: 0.9423 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0295 - precision_74: 0.9898 - recall_74: 0.9907 - val_accuracy: 0.9532 - val_loss: 0.1455 - val_precision_74: 0.9688 - val_recall_74: 0.9366 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0247 - precision_74: 0.9921 - recall_74: 0.9928 - val_accuracy: 0.9556 - val_loss: 0.1353 - val_precision_74: 0.9662 - val_recall_74: 0.9441 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0199 - precision_74: 0.9944 - recall_74: 0.9945 - val_accuracy: 0.9567 - val_loss: 0.1432 - val_precision_74: 0.9594 - val_recall_74: 0.9538 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0173 - precision_74: 0.9947 - recall_74: 0.9954 - val_accuracy: 0.9545 - val_loss: 0.1640 - val_precision_74: 0.9449 - val_recall_74: 0.9652 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0161 - precision_74: 0.9950 - recall_74: 0.9956 - val_accuracy: 0.9553 - val_loss: 0.1516 - val_precision_74: 0.9624 - val_recall_74: 0.9476 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0128 - precision_74: 0.9960 - recall_74: 0.9970 - val_accuracy: 0.9560 - val_loss: 0.1670 - val_precision_74: 0.9671 - val_recall_74: 0.9440 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0106 - precision_74: 0.9966 - recall_74: 0.9978 - val_accuracy: 0.9582 - val_loss: 0.1633 - val_precision_74: 0.9575 - val_recall_74: 0.9589 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0103 - precision_74: 0.9970 - recall_74: 0.9978 - val_accuracy: 0.9581 - val_loss: 0.1587 - val_precision_74: 0.9577 - val_recall_74: 0.9585 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0093 - precision_74: 0.9974 - recall_74: 0.9977 - val_accuracy: 0.9580 - val_loss: 0.1679 - val_precision_74: 0.9591 - val_recall_74: 0.9568 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0086 - precision_74: 0.9974 - recall_74: 0.9979 - val_accuracy: 0.9582 - val_loss: 0.1668 - val_precision_74: 0.9607 - val_recall_74: 0.9555 - learning_rate: 1.0000e-04\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "[최종 모델] 테스트 결과\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE     0.9423    0.9692    0.9555     10000\n",
            "        REAL     0.9683    0.9406    0.9542     10000\n",
            "\n",
            "    accuracy                         0.9549     20000\n",
            "   macro avg     0.9553    0.9549    0.9549     20000\n",
            "weighted avg     0.9553    0.9549    0.9549     20000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}